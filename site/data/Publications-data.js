var publicationsArray = [
	{//38
		namesBeforeRami: "E.Amrani,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "Inbar Shapira, Tal Hakim and A. Bornstein",
		title: "Self-Supervised Object Detection and Retrieval Using Unlabeled Videos,",
		linkTo: "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w56/Amrani_Self-Supervised_Object_Detection_and_Retrieval_Using_Unlabeled_Videos_CVPRW_2020_paper.pdf",
		linkName: "CVPR Workshop on Multimodal Learning, 2020",
		achievement: "",
		imageSource: "CVPRW2020.png",
		abstractContent: "Learning an object detection or retrieval system requires a large data set with manual annotations. Such data are expensive and time-consuming to create and therefore difficult to obtain on a large scale. In this work, we propose using the natural correlation in narrations and the visual presence of objects in video to learn an object detector and retriever without any manual labeling involved. We pose the problem as weakly supervised learning with noisy labels, and propose a novel object detection and retrieval paradigm under these constraints. We handle the background rejection by using contrastive samples and confront the high level of label noise with a new clustering score. Our evaluation is based on a set of ten objects with manual ground truth annotation in almost 5000 frames extracted from instructional videos from the web. We demonstrate superior results compared to state-of-the-art weaklysupervised approaches and report a strongly-labeled upper bound as well. While the focus of the paper is object detection and retrieval, the proposed methodology can be applied to a broader range of noisy weakly-supervised problems."
	},
	{//37
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E.Amrani, O. Azulai, U. Barzelay and D. Rotman",
		title: "TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition,",
		linkTo: "https://arxiv.org/abs/2004.10141",
		linkName: "arXiv, 2020",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//36
		namesBeforeRami: "E.Amrani,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "D. Rotman and A. Bornstein",
		title: "Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning,",
		linkTo: "https://arxiv.org/abs/2003.03186",
		linkName: "arXiv, 2020",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//35
		namesBeforeRami: "T. Shaffter et. al.",
		RamiBenAri: "",
		namesAfterRami: "",
		title: "Evaluation of Combined Artificial Intelligence and Radiologist Assessment to Interpret Screening Mammograms,",
		linkTo: "https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2761795",
		linkName: "JAMA Network Open, 2020.",
		achievement: "This research has been covered by 22 outlets around the globe, totaling more than 36.6 million earned media impressions by March 2020.",
		imageSource: "",
		abstractContent: ""
	},
	{//34
		namesBeforeRami: "E. Amrani,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "T. Hakim and A. Bornstein",
		title: "Toward Self-Supervised Object Detection in Unlabeled Videos,",
		linkTo: "#",
		linkName: "ICCV Workshop on Multimodal Video Analysis and Moments in Time, 2019",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//33
		namesBeforeRami: "R. Bakalo, J. Goldberger and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "T. Hakim and A. Bornstein",
		title: "Weakly and Semi Supervised Detection in Medical Imaging via Deep Dual Branch Net,",
		linkTo: "https://arxiv.org/abs/1904.12589",
		linkName: "arXiv, 2019",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//32
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "Y. Shoshan and T. Tlusty",
		title: "Mammogram Classification with Ordered Loss, Artificial Intelligence in Medicine 2019 (Oral)-20% acceptance rate,",
		linkTo: "data/Publications/OrderedLossAIME2019.pdf",
		linkName: "Paper(PDF)",
		achievement: "Nominated for the best paper award.",
		imageSource: "OrderedLossAIME2019.jpg",
		abstractContent: "Breast radiologists inspect mammograms with the utmost consideration to capture true cancer cases. Yet, machine learning models are typically designed to perform a binary classification, by joining several severities into one positive class. In such scenarios with mixed gradings, a reliable classifier would make less mistakes between distant severities such as missing a true cancer case and calling it as normal or vise versa. To this end, we suggest a simple yet elegant formulation for training a deep learning model with ordered loss, by increasingly weighting the loss of more severe cases, to enforce importance of certain errors over others. Training with the ordered loss yields fewer severe errors and can decrease the chances of missing true cancers. We evaluated our method on mammogram classification, using a weakly supervised deep learning method. Our data set included over 16K mammograms, with a large set of nearly 2,500 biopsy proven cancer cases. Evaluation of our proposed loss function showed a reduction in severe errors of missing true cancers, while preserving overall classification performance in the original task."
	},
	{//31
		namesBeforeRami: "R. Bakalo,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and J. Goldberger",
		title: "Classification and detection in mammogram with weak supervision via dual branch deep neural network,ISBI, 2019 (Oral),",
		linkTo: "data/Publications/WeaklyISBI19.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "isbi2019.jpg",
		abstractContent: "The high cost of generating expert annotations, poses a strong limitation for supervised machine learning methods in medical imaging. Weakly supervised methods may provide a solution to this tangle. In this study, we propose a novel deep learning architecture for multi-class classification of mammograms according to the severity of their containing anomalies, having only a global tag over the image. The suggested scheme further allows localization of the different types of findings in full resolution. The new scheme contains a dual branch network that combines region-level classification with region ranking. We evaluate our method on a large multi-center mammography dataset including ~3,000 mammograms with various anomalies and demonstrate the advantages of the proposed method over a previous weakly supervised strategy."
	},
	{//30
		namesBeforeRami: "T. Tlustly, G. Amit and",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "",
		title: "Unsupervised clustering of mammograms for outlier detection and breast density estimation,ICPR 2018,",
		linkTo: "data/Publications/UnsupervisedMG_ICPR2018_CameraReady.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "icpr2018.jpg",
		abstractContent: "The flourishing of machine learning use for cognitive tasks has driven an increased demand for large annotated training datasets. In the medical imaging domain, such datasets are scarce, and the process of labeling them is costly, error prone and requires high expertise. Unsupervised learning is therefore an attractive approach for analyzing unlabeled medical images. In this paper we describe an unsupervised analysis method, consisting of feature learning by Stacked Auto-Encoders, K-means clustering for building a data model, and encoding of new images using the model. We utilize this method for image-level and patch-level analysis of breast mammograms. At the image-level, we demonstrate that our cluster-based image encoding is able to identify outlier images such as images with implants or non-standard acquisition views. At the patch-level, we show that image signatures using patch clustering can be used for unsupervised semantic segmentation of breast tissues, as well as for separating mammograms with high and low breast density. We evaluate our suggested methods on large datasets and discuss potential applications for data curation, machine-guided annotation and automatic interpretation of medical images."
	},
	{//29
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "Digital Mammography DREAM Challenge: The Core of Top Performing Methods, IEEE Biomedical and Health Informatics - Special Session, March 2018,",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/BHI_Extended_Abstract.pdf",
		linkName: "Extended Abstract(PDF)",
		achievement: "",
		imageSource: "DM_DREAM_Challenge.jpg",
		abstractContent: "The Digital Mammography DREAM (Dialog for Reverse Engineering Assessment and Methods) offered access to an unprecedented amount of curated data. Teams around the globe had the opportunity to tackle the computational diagnosis of screening mammography, with the vision of changing the work-flow for radiologists of the future. This work summarizes the main concepts behind the top performing methods in the competition phase of the challenge."
	},
	{//28
		namesBeforeRami: "A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and E. Barkan",
		title: "A Region Based Convolutional Neural Network for Mass Detection and Classification in Breast Mammography Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization (TCIV), 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//27      need special style
		namesBeforeRami: "Y Choukroun, R Bakalo,",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "A. Akselrod-Ballin, E. Barkan, and P. Kisilev",
		title: "Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network Eurographics Workshop on Visual Computing for Biology and Medicine, 2017",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/WeaklyMIL_EGVCBM17_CRC.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "WeaklyMIL_EGVCBM17_CRC.jpg",
		abstractContent: "Mammography is the common modality used for screening and early detection of breast cancer. The emergence of machine learning, particularly deep learning methods, aims to assist radiologists to reach higher sensitivity and specificity. Yet, typical supervised machine learning methods demand the radiological images to have findings annotated within the image. This is a tedious task, which is often out of reach due to the high cost and unavailability of expert radiologists. We describe a computer aided detection and diagnosis system for weakly supervised learning, where the mammogram (MG) images are tagged only on a global level, without local annotations. Our work addresses the problem of MG classification and detection of abnormal findings through a novel deep learning framework built on the multiple instance learning (MIL) paradigm. Our proposed method processes the MG image utilizing the full resolution, with a deep MIL convolutional neural network. This approach allows us to classify the whole MG according to a severity score and localize the source of abnormality in full resolution, while trained on a weakly labeled data set. The key hallmark of our approach is automatic discovery of the discriminating patches in the mammograms using MIL. We validate the proposed method on two mammogram data sets, a large multi-center MG cohort and the publicly available INbreast, in two different scenarios. We present promising results in classification and detection, comparable to a recent supervised method that was trained on fully annotated data set. As the volume and complexity of data in healthcare continues to increase, such an approach may have a profound impact on patient care in many applications."
	},
	{//26
		namesBeforeRami: "J. Sulam,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and P. Kisilev",
		title: "Maximizing AUC with Deep Learning for Classification of Imbalanced Mammogram Datasets Eurographics Workshop on Visual Computing for Biology and Medicine, 2017",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/MaximizingAUC_MG.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "MaximizingAUC_MG2.jpg",
		abstractContent: "Breast cancer is the second most common cause of death in women. Common computer-aided diagnosis typically demand for carefully annotated data, precise tumor allocation and delineation of the boundaries, which is rarely available in the medical system. In this paper we present a new deep learning approach for classification of mammograms that requires only a global (binary) label. Traditional deep learning methods typically employ classification error losses, which are highly biased by class imbalance – a situation naturally arises in medical classification problems. We hereby suggest a novel loss measure that directly maximizes the Area Under the ROC Curve (AUC), providing an unbiased loss. We validate the proposed model on two mammogram datasets: IMG, comprising of 796 patients, 80 positive (164 images) and 716 negative (1869 images), and the publicly available dataset INbreast. Our results are encouraging, as the proposed scheme achieves an AUC of 0.76 and 0.65 for IMG and INbreast, respectively."
	},
	{//25
		namesBeforeRami: "G. Amit, O. Hadad, S. Alphert, T. Tlusty, Y. Gur,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and S. Hashoul",
		title: "Hybrid Mass Detection in Breast MRI combining Unsupervised Saliency Analysis and Deep Learning MICCAI, 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//24
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "A. Akselrod-Ballin, L. Karlinsky and S. Hashoul",
		title: "Domain Specific Convolutional Neural Nets for Detection of Architectural Distortion in Mammograms ISBI, 2017",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/AD_Detection_ISBI17_final.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "ISBI2017_Rami.jpg",
		abstractContent: "Detection of Architectural distortion (AD) is important for ruling out possible pre-malignant lesions in breast, but due to its subtlety, it is often missed on the screening mammograms. In this work we suggest a novel AD detection method based on region proposal convolution neural nets (R-CNN). When the data is scarce, as typically the case in medical domain, R-CNN yields poor results. In this study, we suggest a new R-CNN method addressing this shortcoming by using a pretrained network on a candidate region guided by clinical observations. We test our method on the publicly available DDSM data set, with comparison to the latest faster R-CNN and previous works. Our detection accuracy allows binary image classification (normal vs. containing AD) with over 80% sensitivity and specificity, and yields 0.46 false-positives per image at 83% true-positive rate, for localization accuracy. These measures significantly improve the best results in the literature."
	},
	{//23
		namesBeforeRami: "O. Hadad, R. Bakalo,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "S. Hashoul and G. Amit",
		title: "Classification of Breast Lesions using Cross-Modal Deep Learning ISBI 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "ISBI2017_Guy.jpg",
		abstractContent: "Automatic detection and classification of lesions in medical images is a desirable goal of many clinical applications. In breast imaging, multiple modalities such as X-ray, ultrasound and MRI are often used in the diagnostic workflow. Training robust classifiers in each modality is challenging due to the typically small size of the available datasets. We propose to use cross-modal transfer learning to improve the robustness of the classifiers. The potential of this approach was demonstrated on a problem of identifying masses in regions of breast MRI images. Comparison between cross-domain and crossmodal transfer learning showed that the latter improved the classification performance, with overall accuracy of 0.93, similar to de-novo training. Using transfer learning within the medical imaging domain may help to roduce standard pretrained shared models, which can be utilized to solve a variety of specific clinical problems."
	},
	{//22
		namesBeforeRami: "G. Amit",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "O. Hadad, E. Monovitch, N. Granot and S. Hashoul",
		title: "Classification of Breast MRI Lesions using Small-Size Training Sets: Comparison to Deep Learning Approaches SPIE-Medical Imaging, 2017",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "SPIE2017_Guy.jpg",
		abstractContent: "Diagnostic interpretation of breast MRI studies requires meticulous work and high expertise. Computerized algorithms may assist radiologists by automatically characterizing the detected lesions. Deep learning approaches have shown promising results in natural image classification, but their applicability to medical imaging is limited by the deficiency of large annotated training sets. In this work, we address automatic classification of breast MRI lesions using two different deep learning approaches. We propose a novel image representation for dynamic contrast enhanced (DCE) breast MRI lesions, which combines the morphological discriminating between benign and malignant lesions: training a designated convolutional neural network and using a pre-trained deep network to extract features for a shallow classifier. The domain-specific trained network provided higher classification accuracy, compared to the pre-trained model, with area under the ROC curve of 0.91 vs. 0.81 and accuracy of 0.83 vs. 0.71. Similar accuracy was achieved in classifying benign lesions, malignant lesions and normal tissue images. The trained network was able to improve by using the multi-channel image representation, and was more robust to reductions in the size of the training set. A small-size convolutional neural network can learn to accurately classify findings in medical images using as little as few hundreds of images from few dozens of patients. With sufficient data augmentation, such network can be trained to outperform a pre-trained out-of-domain classifier. Development of domainspecific deep-learning models for medical imaging may facilitate technological advancements in computeraided diagnosis."
	},
	{//21
		namesBeforeRami: "A. Akselrod-Ballin, L. Karlinsky, S. Alpert, S. Hashoul,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E. Barkan",
		title: "A Region Based Convolutional Network for Tumor Detection and Classification in Breast Mammography MICCAI-DLMIA Workshop, 2016",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "MICCAI-DLMIA2016_Ayelet.jpg",
		abstractContent: "This paper addresses the problem of detection and classification of tumors in breast mammograms. We introduce a novel system that integrates several modules including a breast segmentation module, and a fuzzy logic prior anatomical module for fibroglan ular tissue segmentation into a modified faster regionbased convolutional network. Our method is evaluated on a large multi-center clinical dataset and compared to ground truth annotated by expert radiologists. Preliminary experimental results show the high accuracy and efficiency obtained by the suggested network structure. As the volume and complexity of data in healthcare continues to accelerate generalizing such an approach may have a profound impact on patient care in many applications."
	},
	{//20
		namesBeforeRami: "S. Hashoul, E. Walach, A. Khateeb, A. Walach, G. Amit,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "E. Barkan and P. Kisilev",
		title: "Efficiency of an automatic decision support system in facilitating diagnosis of Thyroid diseases RSNA 2016.",
		linkTo: "#",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//19
		namesBeforeRami: "Y. Frommer,",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "and N. Kiryati",
		title: "Adaptive Shape from Focus with High order Derivatives IMVC 2016",
		linkTo: "#",
		linkName: "",
		achievement: "Best Student Paper",
		imageSource: "",
		abstractContent: ""
	},
	{//18
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari,",
		namesAfterRami: "A. Zlotnick, S. Hashoul",
		title: "A Weakly Labeled Approach for Breast Tissue Segmentation and Breast Density Estimation in Digital Mammography, IEEE International Symposium on Bionmedical Imaging (ISBI) 2016.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_BenAri_FG_Segmentation_ISBI16_Final.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "ISBI2016.jpg",
		abstractContent: "Breast tissue segmentation is a fundamental task in digital mammography. Commonly, this segmentation is applied prior to breast density estimation. However, observations show a strong correlation between the segmentation parameters and the breast density, resulting in a chicken and egg problem. This paper presents a new method for breast segmentation, based on training with weakly labeled data, namely breast density categories. To this end, a Fuzzy-logic module is employed computing an adaptive parameter for segmentation. The suggested scheme consists of a feedback stage where a preliminary segmentation is used to allow extracting domain specific features from an early estimation of the tissue regions. Selected features are then fed into a fuzzy logic module to yield an updated threshold for segmentation. Our evaluation is based on 50 fibroglandular delineated images and on breast density classification, obtained on a large data set of 1243 full-field digital mammograms. The data set contained images from different devices. The proposed analysis provided an average Jaccard spatial similarity coefficient of 0.4 with improvement of this measure in 70\% of cases where the suggested module was applied. In breast density classification, average classification accuracy of 75\% was obtained, which significantly improved the baseline method (67.4\%). Major improvement is obtained in low breast densities where higher threshold levels rejects false positive regions. These results show a promise for the clinical application of this method in breast segmentation, without the need for laborious tissue annotation."
	},
	{//17
		namesBeforeRami: "Y. Frommer,",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Kiryati",
		title: "Shape from Focus with Adaptive Focus Measure and High Order Derivatives, BMVC 2015,",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/adaptiveSFF_BMVC15.pdf",
		linkName: "Paper(PDF)",
		achievement: "",
		imageSource: "BMVC15.jpg",
		abstractContent: "Shape From Focus (SFF) methods frequently use a single focus measure to obtain a depth map. Common focus measures are fixed and spatially invariant. In this paper we present a framework to create an adaptive focus measure based on ensemble of basis focus operators. Using the proposed framework we derive a new spatially variant focus measure obtained from linear combination of image derivatives. This approach effectively generalizes some of the existing measures. A new measure emerged from the proposed framework includes high order derivatives and presents a highly reliable focus measure. We rely on the focus curve standard deviation (CSTD) to determine the linear coefficients in our model. The emerged focus measure copes effectively with texture variation, strong intensity edges and depth discontinuities. Using CSTD we further suggest a new approach for aggregation in the focus volume succeeded by reconstruction based on the focus curve centroid. This different approach of aggregation and reconstruction yields improved depth maps, respecting shape smoothness and depth discontinuities for diversity of textured images. We assess the performance of our new approach by extensive experiments with highly realistic synthetic images and real images including two unique cases captured in the wild. In terms of focus measure, we significantly outperform the state-of-the-art, while presenting superior results comparing to two previously published alternatives."
	},
	{//16
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "A Unified Approach for Registration and Depth in Depth from Defocus, IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(6), pp. 1041-1055, 2014.",
		linkTo: "https://ieeexplore.ieee.org/document/6702415?tp=&arnumber=6702415&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6702415",
		linkName: "Publisher Link,",
		link2To: "https://www.cs.bgu.ac.il/~rba/Papers/RBenAri_dfd_TPAMI14.pdf",
		link2Name: "Paper(PDF),",
		link3To: "https://www.cs.bgu.ac.il/~rba/Papers/supplementaryMaterial_TPAMI14",
		link3Name: "Supplementary Material(PDF),",
		link4To: "ProjectPageDFD.html",// "https://www.cs.bgu.ac.il/~rba/dfd/DFDProjectPage.html", "data/Publications/ProjectPages/DFD/DFDProjectPage.html"
		link4Name: "Project Page.",
		achievement: "Editor's selection for spotlight paper",
		imageSource: "web_teaserdfd_regis.png",
		abstractContent: "Depth from Defocus (DFD) suggests a simple optical set-up to recover the shape of a scene through imaging with shallow depth of field. Although numerous methods have been proposed for DFD, less attention has been paid to the particular problem of alignment between the captured images. The inherent shift-variant defocus often prevents standard registration techniques from achieving the accuracy needed for successful shape reconstruction. In this paper, we address the DFD and registration problem in a unified framework, exploiting their mutual relation to reach a better solution for both cues. We draw a formal connection between registration and defocus blur, find its limitations and reveal the weakness of the standard isolated approaches of registration and depth estimation. The solution is approached by energy minimization. The efficiency of the associated numerical scheme is justified by showing its equivalence to the celebrated Newton-Raphson method and proof of convergence of the emerged linear system. The computationally intensive approach of DFD, newly combined with simultaneous registration, is handled by GPU computing. Experimental results demonstrate the high sensitivity of the recovered shapes to slight errors in registration and validate the superior performance of the suggested approach over two, separately applying registration and DFD alternatives."
	},
	{//15
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A computationally efficient tracker with direct appearance-kinematic measure and adaptive Kalman filter, Journal of Real-Time Image Processing, online March 2013.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_JRTIP2013.pdf",
		linkName: "Preprint(PDF),",
		link2To: "ProjectPageTracking.html",// data/Publications/ProjectPages/Tracking/Project.html
		link2Name: "Project Page",
		achievement: "",
		imageSource: "DallasCarChase.gif",
		abstractContent: "Depth from Defocus (DFD) suggests a simple optical set-up to recover the shape of a scene through imaging with shallow depth of field. Although numerous methods have been proposed for DFD, less attention has been paid to the particular problem of alignment between the captured images. The inherent shift-variant defocus often prevents standard registration techniques from achieving the accuracy needed for successful shape reconstruction. In this paper, we address the DFD and registration problem in a unified framework, exploiting their mutual relation to reach a better solution for both cues. We draw a formal connection between registration and defocus blur, find its limitations and reveal the weakness of the standard isolated approaches of registration and depth estimation. The solution is approached by energy minimization. The efficiency of the associated numerical scheme is justified by showing its equivalence to the celebrated Newton-Raphson method and proof of convergence of the emerged linear system. The computationally intensive approach of DFD, newly combined with simultaneous registration, is handled by GPU computing. Experimental results demonstrate the high sensitivity of the recovered shapes to slight errors in registration and validate the superior performance of the suggested approach over two, separately applying registration and DFD alternatives."
	},
	{//14
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and G. Raveh",
		title: "Variational Depth from Defocus in Real-Time, The 3rd IEEE Workshop on GPU for Computer Vision ICCV, pp. 522-529, November 2011, Barcelona.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_BenAri_PrePrint_ICCV11.pdf",
		linkName: "Preprint(PDF),",
		link2To: "https://www.cs.bgu.ac.il/~rba/Papers/R_BenAri_Presen_ICCV11.pdf",
		link2Name: "Presentation(PDF)",
		achievement: "",
		imageSource: "DFD_set.jpg",
		abstractContent: "With emerging of next generation of digital cameras offering a 3D reconstruction of a viewed scene, Depth from Defocus (DFD) presents an attractive option. In this approach the depth profile of the scene is recovered from two views captured in different focus setting. The DFD is well known as a computationally-intensive method due to the shift-variant filtering involved with its estimation. In this paper we present a parallel GPGPU implementation of DFD based on the variational framework, enabling computation up to 15 frames/sec for a SVGA sequence. This constitutes the first GPU application and the fastest implementation known for passive DFD. The speed-up is obtained by using the novel Fast Explicit Diffusion approach and the fine grain data parallelism in an explicit scheme. We evaluate our method on publicly available real data and compare its results to a recently published PDE based method. The proposed method outperforms previous DFD techniques in terms of accuracy/runtime, suggesting the DFD as an alternative for 3D reconstruction in real-time."
	},
	{//13
		namesBeforeRami: "S. Cohen and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "Image de-noising by Bayesian regression, 16th Int. Conference on Image Analysis and Processing (ICIAP), September 2011, Italy",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/Bayesian_Denoising_v7.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "Denoising_set.jpg",
		abstractContent: "We present a kernel based approach for image de-noising in the spatial domain. The crux of evaluation for the kernel weights is addressed by a Bayesian regression. This approach introduces an adaptive filter, well preserving edges and thin structures in the image. The hyper-parameters in the model as well as the predictive distribution functions are estimated through an efficient iterative scheme. We evaluate our method on common test images, contaminated by white Gaussian noise. Qualitative results show the capability of our method to smooth out the noise while preserving the edges and fine texture. Quantitative comparison with the celebrated total variation (TV) and several wavelet methods ranks our approach among state-of-the-art denoising algorithms. Further advantages of our method include the capability of direct and simple integration of the noise PDF into the de-noising framework. The suggested method is fully automatic and can equally be applied to other regression problems."
	},
	{//12
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A Prediction based Fast and Robust Tracker, Israel Machine Vision Conference, 2011.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//11
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Stereo Matching with Mumford-Shah Regularization and Occlusion Handling, IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(11), pp. 2071-2084, 2010.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_Stereo_TPAMI10.pdf",
		linkName: "Preprint(PDF)",
		achievement: "Editor's selection for spotlight paper on the TPAMI Nov. 2010 Edition.<br>Performance ranked 4th out of 55 in the Middlebury Benchmark of Feb 2009, (Algo. VarMSOH - error threshold=0.5).",
		imageSource: "Stereo_TPAMI10.jpg",
		abstractContent: "This paper addresses the problem of correspondence establishment in binocular stereo vision. We suggest a novel spatially continuous approach for stereo matching based on the variational framework. The proposed method suggests a unique regularization term based on Mumford-Shah functional for discontinuity preserving, combined with a new energy functional for occlusion handling. The evaluation process is based on concurrent minimization of two coupled energy functionals, one for domain segmentation (occluded vs. visible) and the other for disparity evaluation. In addition to a dense disparity map, our method also provides estimation for the half-occlusion domain, and a discontinuity function allocating the disparity/depth boundaries. Two new constraints are introduced improving the revealed discontinuity map. The experimental tests include a wide range of real data sets from Middlebury stereo database. The results demonstrate the capability of our method in calculating an accurate disparity function with sharp discontinuities and occlusion map recovery. Significant improvements are shown comparing to a recently published variational stereo approach. A comparison on the Middlebury stereo benchmark with sub-pixel accuracies shows that our method is currently among the top-ranked stereo matching algorithms."
	},
	{//10
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and O. Ben-Shahar",
		title: "A Real-Time and Robust Tracker for Robot Vision, The 3rd Israeli Conference on Robotics, 2010.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//9
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N.Sochen",
		title: "A Geometric Framework and a New Criterion in Optical Flow Modeling, Journal of Mathematical Imaging and Vision, 33(2), pp. 178-194, February 2009.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_Aligned_OF_JMIV09.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "OF_JMIV09.jpg",
		abstractContent: "We evaluate the dense optical flow between two frames via variational approach. In this paper, a new framework for deriving the regularization term is introduced giving a geometric insight into the action of a smoothing term. The framework is based on the Beltrami paradigm in image denoising. It includes a general formulation that unifies several previous methods. Using the proposed framework we also derive two novel anisotropic regularizers incorporating a new criterion that requires co-linearity between the gradients of optical flow components and possibly the intensity gradient. We call this criterion &ldquo;alignment&rdquo; and reveal its existence also in the celebrated Nagel and Enkelmann&rsquo;s formulation. It is shown that the physical model of rotational motion of a rigid body, pure divergent/convergent flow and irrotational fluid flow, satisfy the alignment criterion in the flow field. Experimental tests in comparison to a recently published method show the capability of the new criterion in improving the optical flow estimations."
	},
	{//8
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N.Sochen",
		title: "A Geometric Framework for Regularization of the Data Term in Stereo Vision, Journal of Mathematical Imaging and Vision, 331(1), pp. 17-33, May 2008.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_RegDataTerm_JMIV08.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "Stereo_JMIV08.jpg",
		abstractContent: "Every stereovision application must cope with the correspondence problem. The space of the matching variables, often consisting of spatial coordinates, intensity and disparity, is commonly referred as the data term (space). Since the data is often noisy a-priori preference is required constraining the evaluated disparity to be smooth (or piecewise smooth). It is shown that in the early local methods (e.g. window correlation techniques) a regularization is conducted on the data space. In the other hand, recent global methods consider a non-regularized data term with an added smoothing constraint implemented directly on the disparity. In this paper, we propose a new idea combining between the two latter approaches. To this end a novel geometric method for regularization of the data space is presented. The idea is then implemented on the state of the art variational method. Experimental results on the Middlebury real images demonstrate the qualitative and quantitative potential of the proposed approach."
	},
	{//7
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and D. Aiger",
		title: "Geodesic Active Contours with Combined Shape and Appearance Priors, In Proc. Advanced Concepts in Intelligent Vision Systems (ACIVS), vol. 5259 of LNCS, pp. 494-505, 2008.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_ACIVS08.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "ACIVS08.jpg",
		abstractContent: "We present a new object segmentation method that is based on geodesic active contours with combined shape and appearance priors. It is known that using shape priors can significantly improve object segmentation in cluttered scenes and occlusions. Within this context, we add a new prior, based on the appearance of the object, (i.e., an image) to be segmented. This method enables the appearance pattern to be incorporated within the geodesic active contour framework with shape priors, seeking for the object whose boundaries lie on high image gradients and that best fits the shape and appearance of a reference model. The output contour results from minimizing an energy functional built of these three main terms. We show that appearance is a powerful term that distinguishes between objects with similar shapes and capable of successfully segment an object in a very cluttered environment where standard active contours (even those with shape priors) tend to fail."
	},
	{//6
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Variational Stereo Vision with Sharp Discontinuities and Occlusion Handling, In Proc. IEEE International Conference on Computer Vision (ICCV), pp. 1-7, 2007.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_ICCV07.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "ICCV07.jpg",
		abstractContent: "This paper addresses the problem of correspondence establishment in binocular stereo vision. We suggest a novel variational approach that considers both the discontinuities and occlusions. It deals with color images as well as gray levels. The proposed method divides the image domain into the visible and occluded regions where each region is handled differently. The depth discontinuities in the visible domain are preserved by use of the total variation term in conjunction with the Mumford-Shah framework. In addition to the dense disparity and the occlusion maps, our method also provides a discontinuity function revealing the location of the boundaries in the disparity map. We evaluate our method on data sets from Middlebury site showing superior performance in comparison to the state of the art variational technique."
	},
	{//5
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "A General Framework and New Alignment Criterion for Dense Optical Flow, In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, pp. 529-536, 2006.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_CVPR06.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "CVPR06.jpg",
		abstractContent: "The problem of dense optical flow computation is addressed from a variational viewpoint. A new geometric framework is introduced. It unifies previous art and yields new efficient methods. Along with the framework a new alignment criterion suggests itself. It is shown that the alignment between the gradients of the optical flow components and between the latter and the intensity gradients is an important measure of the flow's quality. Adding this criterion as a requirement in the optimization process improves the resulting flow. This is demonstrated in synthetic and real sequences."
	},
	{//4
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and N. Sochen",
		title: "Non-Isotropic Regularization of the Correspondence Space in Stereo Vision, In Proc. Int. Conference in Pattern Recognition (ICPR), vol. 4, pp. 293-296, 2004.",
		linkTo: "https://www.cs.bgu.ac.il/~rba/Papers/R_Ben-Ari_ICPR04.pdf",
		linkName: "Preprint(PDF)",
		achievement: "",
		imageSource: "ICPR04.jpg",
		abstractContent: "The correspondence problem in stereo vision is notoriously difficult. In many approaches a noisy solution is extracted from the correspondence space. Various sophisticated regularization techniques are applied then on this noisy solution. We study here the possibility to denoise the correspondence/correlation space before extracting the solution, by a non-linear and non-isotropic scheme. We show that this methods preserves edges (depth discontinuities) well and overcomes some of the problems encountered in previous approaches."
	},
	// In Aerospace Sciences
	{//3
		namesBeforeRami: "A. Rosen and",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "",
		title: "A Mathematical Modeling of Helicopter Track and Balance &ndash; Theory, Journal of Sound and Vibration, vol. 200(5), pp. 589-603, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//2
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and A. Rosen",
		title: "A Mathematical Modeling of Helicopter Track and Balance &ndash; Results, Journal of Sound and Vibration, vol. 200(5), pp. 605-620, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	},
	{//1
		namesBeforeRami: "",
		RamiBenAri: "Rami Ben-Ari",
		namesAfterRami: "and A. Rosen",
		title: "Investigation of Helicopter Rotor Track and Balance, In Proc. of 37th Israel Annual Conference on Aerospace Sciences, pp. 308-319, 1997.",
		linkTo: "",
		linkName: "",
		achievement: "",
		imageSource: "",
		abstractContent: ""
	}
];